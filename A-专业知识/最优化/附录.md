

**梯度:gradient (vector)**
$$
g(x) = \nabla f=\left[ \begin{aligned}& \frac{\partial f}{\partial {{x}_{1}}} \\& \frac{\partial f}{\partial {{x}_{2}}} \\& \vdots  \\& \frac{\partial f}{\partial {{x}_{n}}} \\\end{aligned} \right]
$$
**海森矩阵: Hessian (matrix)**
$$
H(x)={{\nabla }^{2}}f(x)=\nabla ({{\nabla }^{T}}f(x))=\left[ \begin{matrix}\frac{{{\partial }^{2}}f}{\partial x_{1}^{2}} & \frac{{{\partial }^{2}}f}{\partial {{x}_{1}}\partial {{x}_{2}}} & \cdots  & \frac{{{\partial }^{2}}f}{\partial {{x}_{1}}\partial {{x}_{n}}}  \\\frac{{{\partial }^{2}}f}{\partial{{x}_{2}}\partial {{x}_{1}}} & \frac{{{\partial }^{2}}f}{\partial x_{2}^{2}} & \cdots  & \frac{{{\partial }^{2}}f}{\partial {{x}_{2}}\partial {{x}_{n}}}  \\\vdots  & \vdots  & \ddots  & \vdots   \\\frac{{{\partial }^{2}}f}{\partial {{x}_{n}}\partial {{x}_{1}}} & \frac{{{\partial }^{2}}f}{\partial{{x}_{n}}\partial {{x}_{2}}} & \cdots  & \frac{{{\partial }^{2}}f}{\partial x_{n}^{2}}  \\\end{matrix} \right]
$$


泰勒公式

> 由泰勒公式可知，如果一个函数足够平滑，在已知函数在某一点的各阶导数值的情况之下，泰勒公式可以用这些导数值做系数构建一个多项式来近似函数在这一点的邻域中的值。泰勒公式还给出了这个多项式和实际的函数值之间的偏差。

对于一个一元函数来说，泰勒公式可写为下式
$$
\begin{aligned}& f(x)=f({{x}_{0}})+{f}'({{x}_{0}})(x-{{x}_{0}})+\frac{{f}''({{x}_{0}})}{2!}{{(x-{{x}_{0}})}^{2}}+ \\& \text{          }...+\frac{{{f}^{(n)}}({{x}_{0}})}{n!}{{(x-{{x}_{0}})}^{n}}+\frac{{{f}^{(n+1)}}({{x}_{0}})}{(n+1)!}{{({{x}_{0}}+\theta (x-{{x}_{0}}))}^{n+1}} \\\end{aligned}
$$
其中$0<𝜃<1$，$𝑥_0+𝜃(𝑥−𝑥_0)=𝜉$其实𝜉就表示$𝑥_0$与𝑥之间的任意一点。

现实中描述一个问题的时候，一般都有多个输入变量；在工程中一般认为展开到二阶导数就能精确的表示点$𝐱_𝑘$周围任意一点$𝐱_𝑘+𝛿$的函数值$𝑓(𝐱_𝑘+𝛿)$，则有：
$$
\begin{aligned} & f({{\mathbf{x}}_{k}}+\mathbf{\delta })=f({{\mathbf{x}}_{k}})+{f}'({{\mathbf{x}}_{k}})\mathbf{\delta }+\frac{1}{2}{{\mathbf{\delta }}^{T}}{f}''({{\mathbf{x}}_{k}})\mathbf{\delta }+O\left( {{\left\| \mathbf{\delta } \right\|}^{3}} \right) \\& \text{               =}f({{\mathbf{x}}_{k}})+{{\nabla }^{T}}f({{\mathbf{x}}_{k}})\cdot \mathbf{\delta }+\frac{1}{2}{{\mathbf{\delta }}^{T}}\cdot {{\nabla }^{2}}f({{\mathbf{x}}_{k}})\cdot \mathbf{\delta }+O\left( {{\left\| \mathbf{\delta } \right\|}^{3}} \right) \\\end{aligned}
$$

> 其中一次，二次项均为标量



矩阵内积
$$
A\cdot B=trace(AB)=\sum^n_{i=1}\sum^n_{j=1} a_{ij}b_{ij}
$$
