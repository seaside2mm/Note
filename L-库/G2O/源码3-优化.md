
[g2o 学习笔记](https://www.jianshu.com/p/e16ffb5b265d)
[非线性优化（三）：g2o源代码](https://zhuanlan.zhihu.com/p/100522179)

  
# 类关系



<p align="center">

  <img src="https://raw.githubusercontent.com/seaside2mm/github-photos/master/images/20221006152048.png"  width="200%"/>

</p>

  

---

  
  

## SparseOptimizer

[SparseOptimizer](https://github.com/RainerKuemmerle/g2o/blob/master/g2o/core/sparse_optimizer.h)继承自`OptimizableGraph`，是优化时的具体操作对象。到了这一步，SparseOptimizer更加具体，并且不再包含具体的`Vertex`或者`Edge`，而是作为图优化的`interface`，实现具体的功能。

  

* 第一大类别函数是优化的初始化函数`initializeOptimization`.

  * 最简单的就是通过设置level来优化不同层次的图。

  * 此外，还可以通过设置特定的节点或边来初始化要优化的对象（一部分图）。

  * 以设置节点为例，函数遍历所有节点，和该节点对应的边，把相关节点和被设置为`level`（默认是0）的边添加到`_activeVertices`和`_activeEdges`，供后续算法优化。这样，就实现了`mulit-level optimization`。

  * 还有`setAlgorithm`来设置对应的优化算法。

```c++

  /**
   * Initializes the structures for optimizing a portion of the graph specified
   * by a subset of edges. Before calling it be sure to invoke marginalized()
   * and fixed() to the vertices you want to include in the schur complement or
   * to set as fixed during the optimization.
   * @param eset: the subgraph to be optimized.
   * @returns false if somethings goes wrong
   */
  virtual bool initializeOptimization(HyperGraph::EdgeSet& eset)
  virtual bool initializeOptimization(HyperGraph::VertexSet& vset,
                                      int level = 0);
  /**
   * Initializes the structures for optimizing the whole graph.
   * Before calling it be sure to invoke marginalized() and fixed() to the
   * vertices you want to include in the schur complement or to set as fixed
   * during the optimization.
   * @param level: is the level (in multilevel optimization)
   * @returns false if somethings goes wrong
   */
  virtual bool initializeOptimization(int level = 0);

```

  
* 另一大类别函数为辅助函数。
  * 如`findGauge`和`gaugeFreedom`函数可以找到维度最大的节点，或返回、或将之fix住来减小自由度，从而使得优化算法可行；
  * 或是`update`函数、`computeActiveError`函数等来单次更新节点、计算误差；
  * 或是findActiveEdge等来获得激活边等变量信息。

* 最后就是优化函数`optimize`。
  * 内部使用一个`OptimizationAlgorithm`类型的变量`_algorithm`来进行具体的优化计算。
  * 并根据之前的用户设置，如`setVerbose`, `setComputeBatchStatistics`来决定是否记录中间结果和统计信息等。

## OptimizationAlgorithm

是一个虚基类，它定义了一个优化器的大部分接口，如init, computeMarginals和solve等，这些都是虚函数，需要对应的派生类来进行实现。

OptimizationAlgorithmWithHessian是OptimizationAlgorithm的派生类，但由于没有实现solve这个最重要的虚函数，因此它仍然是一个虚基类。

它最重要的功能有两点。一个是定义了一个线性求解器_solver（Solver类，即我们刚开始说的第三层），后续派生类中，具体的矩阵求解等就通过这个线性求解器来完成。第二个就是这个虚派生类实现了OptimizationAlgorighm中的一部分虚函数，如init, computeMarginals（其实也是调用_solver来实现）等。以init函数为例，算法会遍历当前的activeVertices，如果有需要进行边缘化的节点，并且对应的线性求解器也支持Schur补，则会进行边缘化，并调用_solver的初始化函数来进行初始化。

g2o提供了三种优化算法：GN，LM和dog-leg，各是一个类，最主要的函数都是solve函数。但由于优化算法的不同，因此内部实现都不一样。要注意的是，优化算法的迭代和停止判断都是在外部SparseOptimizer类中的optimize函数中判断，这三种优化算法只负责解当前的迭代步骤。

最后，线性求解器LinearSolver是一个模板虚基类。它是solvers文件夹下各个线性求解器的interface. 它还有一个派生类LinearSolverCCS，主要是利用迭代的方式（如PCG）来对线性系统进行求解。

这里就不详细介绍了。比较简单的求解器有LinearSolverDense，大概介绍下让大家对这个先行求解器有所了解。

顾名思义，LinearSolverDense是用来求解一个稠密矩阵的，比如舒尔补之后的机器人位姿矩阵。的solve函数中，先准备好一个矩阵_H（传给_linearSolver的海塞矩阵H在solve函数的形参名称为A，可以认为是H的CRS存储形式（一种矩阵存储方式），所以这里面是在求Ax=b的解），这里假设传入的A矩阵是一个稀疏矩阵，并且按照CRS的方式存储。因此需要将A矩阵恢复成一个真正的ｍ＊ｎ大小的矩阵，存放在_H中。最后，调用Eigen中的Cholesky分解来求解Ax=b，并返回最后的结果。

## Solver

  

线性求解器`Solver`类是一个虚基类

```c++

/**
 * \brief Generic interface for a sparse solver operating on a graph which
 * solves one iteration of the linearized objective function
 */
class G2O_CORE_API Solver {
    SparseOptimizer* _optimizer;
    number_t* _x;
    number_t* _b;
    size_t _xSize, _maxXSize;
    bool _isLevenberg;
```

包括用于求解器初始化的`init`, `buildStructure`和`buildSystem`函数等；

求解$Ax=b$的`solve()`函数；和一些辅助函数：`_x`和`_b`的`get`，图`_optimizer`的`set`和`get`，和`levenberg`法相关的设置`lambda`等函数。

  
  
  
  

## BlockSolver

  

Solver的主要派生类是`BlockSolver`类。

  

```c++

/**
 * \brief Implementation of a solver operating on the blocks of the Hessian
 */
/// BlockSolver
template <typename Traits>
class BlockSolver: public BlockSolverBase
{
  public:
    /**
     * allocate a block solver ontop of the underlying linear solver.
     * NOTE: The BlockSolver assumes exclusive access to the linear solver and will therefore free the pointer
     * in its destructor.
     */
    BlockSolver(std::unique_ptr<LinearSolverType> linearSolver);
    virtual bool init(SparseOptimizer* optmizer, bool online = false);
    virtual bool buildStructure(bool zeroBlocks = false);
    virtual bool updateStructure(const std::vector<HyperGraph::Vertex*>& vset, const HyperGraph::EdgeSet& edges);
    virtual bool buildSystem();
    virtual bool solve();
    virtual bool computeMarginals(SparseBlockMatrix<MatrixX>& spinv, const std::vector<std::pair<int, int> >& blockIndices);
    virtual bool setLambda(number_t lambda, bool backup = false);
    virtual void restoreDiagonal();
    virtual bool supportsSchur() {return true;}
    virtual bool schur() { return _doSchur;}
    virtual void setSchur(bool s) { _doSchur = s;}
    LinearSolver<PoseMatrixType>& linearSolver() const { return *_linearSolver;}
    virtual void multiplyHessian(number_t* dest, const number_t* src) const { _Hpp->multiplySymmetricUpperTriangle(dest, src);}
  protected:
    void resize(int* blockPoseIndices, int numPoseBlocks,
        int* blockLandmarkIndices, int numLandmarkBlocks, int totalDim);
    ////////////////////////////////////////////////////////////////////////////////////
    // Build linear system about solution increments Δx
    // H*Δx = -b
    //
    // coefficient matrix are divided into blocks, and each block is calculated
    // | Hpp  Hpl ||Δxp| = |-bp|
    // | HplT Hll ||Δxl|   |-bl|
    ////////////////////////////////////////////////////////////////////////////////////
    std::unique_ptr<SparseBlockMatrix<PoseMatrixType>> _Hpp;
    std::unique_ptr<SparseBlockMatrix<LandmarkMatrixType>> _Hll;
    std::unique_ptr<SparseBlockMatrix<PoseLandmarkMatrixType>> _Hpl;
    // schur complement of the H matrix
    // HSc = Hpp - Hpl*inv(Hll)*HplT
    // bSc = -bp + Hpl*inv(Hll)*bl
    std::unique_ptr<SparseBlockMatrix<PoseMatrixType>> _Hschur;
    std::unique_ptr<SparseBlockMatrixDiagonal<LandmarkMatrixType>> _DInvSchur;
    std::unique_ptr<SparseBlockMatrixCCS<PoseLandmarkMatrixType>> _HplCCS;
    std::unique_ptr<SparseBlockMatrixCCS<PoseMatrixType>> _HschurTransposedCCS;
    //
    std::unique_ptr<LinearSolverType> _linearSolver;
    std::vector<PoseVectorType, Eigen::aligned_allocator<PoseVectorType> > _diagonalBackupPose;
    std::vector<LandmarkVectorType, Eigen::aligned_allocator<LandmarkVectorType> > _diagonalBackupLandmark;
    bool _doSchur;
    std::unique_ptr<number_t[], aligned_deleter<number_t>> _coefficients;
    std::unique_ptr<number_t[], aligned_deleter<number_t>> _bschur;
    int _numPoses, _numLandmarks;
    int _sizePoses, _sizeLandmarks;
};

```

  
  

这是一个模板类，其模板参数是另一个模板类`BlockSolverTraits`。这是一个很常见的用法，`BlockSolverTraits`的两个模板参数分别是位姿的维度`_poseDim`和路标点的维度`_landmarkDim`，里面主要是定义了各种类型，如下：

  

```cpp

// traits to summarize the properties of the fixed size optimization
template <int _PoseDim, int _LandmarkDim>
struct BlockSolverTraits
{

  static const int PoseDim = _PoseDim;

  static const int LandmarkDim = _LandmarkDim;

  

  typedef Eigen::Matrix<number_t, PoseDim, PoseDim, Eigen::ColMajor> PoseMatrixType;

  typedef Eigen::Matrix<number_t, LandmarkDim, LandmarkDim, Eigen::ColMajor> LandmarkMatrixType;

  typedef Eigen::Matrix<number_t, PoseDim, LandmarkDim, Eigen::ColMajor> PoseLandmarkMatrixType;

  

  typedef Eigen::Matrix<number_t, PoseDim, 1, Eigen::ColMajor> PoseVectorType;

  typedef Eigen::Matrix<number_t, LandmarkDim, 1, Eigen::ColMajor> LandmarkVectorType;

  

  typedef SparseBlockMatrix<PoseMatrixType> PoseHessianType;

  typedef SparseBlockMatrix<LandmarkMatrixType> LandmarkHessianType;

  typedef SparseBlockMatrix<PoseLandmarkMatrixType> PoseLandmarkHessianType;

  typedef LinearSolver<PoseMatrixType> LinearSolverType;

};

/// BlockSolverPL
/// P表示的是Pose的维度（注意一定是流形manifold下的最小表示），
/// L表示Landmark的维度。
template<int p, int l>
using BlockSolverPL = BlockSolver< BlockSolverTraits<p, l> >;
// variable size solver
using BlockSolverX = BlockSolverPL<Eigen::Dynamic, Eigen::Dynamic>;
// solver for BA/3D SLAM
using BlockSolver_6_3 = BlockSolverPL<6, 3>;
// solver fo BA with scale
using BlockSolver_7_3 = BlockSolverPL<7, 3>;
// 2Dof landmarks 3Dof poses
using BlockSolver_3_2 = BlockSolverPL<3, 2>;

```
  

这里思考一个问题，假如说在某个应用下，我们的P和L在程序开始并不能确定（例如程序中既有映射关系的边，同时还有位姿图之间的边，这时候的HppHpp矩阵将不是那么的稀疏），那么此时这个块状求解器如何定义呢？其实也比较简单，g2o已经帮我们定义了一个不定的BlockSolverTraits，所有的参数都在中间过程中被确定，那么为什么g2o还帮助我们定义了一些常用的类型呢？一种可能是出于节约初始化时间的角度出发的，但是个人估计不是很靠谱，毕竟C++申请出一块内存应该还是很快的，没有必要为了这点儿时间纠结；那么另一种也许就是作者想把常用的类型定义出来而已吧～

  
  

## LinearSolver

最后，线性求解器LinearSolver是一个模板虚基类。它是solvers文件夹下各个线性求解器的interface. 它还有一个派生类LinearSolverCCS，主要是利用迭代的方式（如PCG）来对线性系统进行求解。

  

这里就不详细介绍了。比较简单的求解器有LinearSolverDense，大概介绍下让大家对这个先行求解器有所了解。

  

顾名思义，LinearSolverDense是用来求解一个稠密矩阵的，比如舒尔补之后的机器人位姿矩阵。的solve函数中，先准备好一个矩阵_H（传给_linearSolver的海塞矩阵H在solve函数的形参名称为A，可以认为是H的CRS存储形式（一种矩阵存储方式），所以这里面是在求Ax=b的解），这里假设传入的A矩阵是一个稀疏矩阵，并且按照CRS的方式存储。因此需要将A矩阵恢复成一个真正的ｍ＊ｎ大小的矩阵，存放在_H中。最后，调用Eigen中的Cholesky分解来求解Ax=b，并返回最后的结果。

  

```c++

/**

 * \brief basic solver for Ax = b

 *

 * basic solver for Ax = b which has to reimplemented for different linear

 * algebra libraries. A is assumed to be symmetric (only upper triangular block

 * is stored) and positive-semi-definite.

 */

template <typename MatrixType>

class LinearSolver

```

  
  

# initializeOptimization函数

  

```c++

bool SparseOptimizer::initializeOptimization(HyperGraph::VertexSet& vset, int level)

```

`initializeOptimization()`方法采用顶点子集或边子集，这些边将被考虑用于下一次优化运行。 此外，可以考虑所有顶点和边进行优化。 我们分别引用当前被视为活动顶点(active vertices)和边的顶点和边。

  

在初始化过程中，优化器（optimizer）为每个活动顶点分配一个**临时索引**(temporary index)。 该临时索引对应于Hessian中的顶点的块列/行。 在优化过程中，某些顶点可能需要保持固定，以解决任意自由度（规范自由度,gauge freedom)。 这可以通过设置顶点的`_fixed`属性来完成。

  

流程如下：

* 把所有的顶点（Vertex）插入到`vset`的集合中（set不用担心插入了相同的顶点）

* 遍历`vset`集合，取出每个顶点的边,并判断边所连接的顶点是否都是有效的(边对应顶点数不够or图中没有边的顶点了)，如果是，则认为这是一个有效的边和顶点，并分别加入到`_activeEdges`和`_activeVertices`中

> 这里每个边都有一个`level`的概念，默认情况下，g2o只处理`level=0`的边，在orbslam中，如果确定某个边的重投影误差过大，则把level设置为1，也就是舍弃这个边对于整个优化的影响

* 对上述的`_activeEdges`和`_activeVertices`按照`ID`号进行排序，其中`Vertex`的`ID`号是自己设置的，而`Edge`的`ID`号是g2o内部有个变量进行赋值的

* 对于上述的`_activeVertices`，剔除掉固定点`fixed`之后，把所有的顶点按照不被`margin `在前，被`margin`在后的顺序排成vector类型，变量为`_ivMap`，这个变量很重要，基本上后面的所有程序都是用这个变量进行遍历的

  



```cpp

bool SparseOptimizer::initializeOptimization(HyperGraph::VertexSet& vset, int level){

  

  for (HyperGraph::VertexSet::iterator it=vset.begin(); it!=vset.end(); ++it){

    OptimizableGraph::Vertex* v= (OptimizableGraph::Vertex*) *it;

    const OptimizableGraph::EdgeSet& vEdges=v->edges();

  

    // count if there are edges in that level. If not remove from the pool

    int levelEdges=0;

    for (OptimizableGraph::EdgeSet::const_iterator it=vEdges.begin(); it!=vEdges.end(); ++it){

      OptimizableGraph::Edge* e=reinterpret_cast<OptimizableGraph::Edge*>(*it);

      if (level < 0 || e->level() == level) {

        if (allVerticesOK && !e->allVerticesFixed()) {

          auxEdgeSet.insert(e);

          levelEdges++;

        }

      }

    }

    if (levelEdges){

      _activeVertices.push_back(v);  //

    }

  }

  

  for (set<Edge*>::iterator it = auxEdgeSet.begin(); it != auxEdgeSet.end(); ++it)

    _activeEdges.push_back(*it); //

}

  

```

</details>

  

# optimize函数

  
  

```c++

int SparseOptimizer::optimize(int iterations, bool online) {

  ok = _algorithm->init(online);

  for (int i = 0; i < iterations && !terminate() && ok; i++) {

    result = _algorithm->solve(i, online);

  }

  return cjIterations;

}

```

核心主要是调用`_algorithm`的`solve`函数。



```cpp

template <typename Traits>

bool BlockSolver<Traits>::buildStructure(bool zeroBlocks)

  

template <typename Traits>

bool BlockSolver<Traits>::buildSystem()

  

template <typename Traits>

bool BlockSolver<Traits>::solve(){

```
  

## buildStructure

  

中间层的优化算法调用线性求解器时，如果是第一次迭代，那么要调用buildStructure来构建Hx=b这样一个线性系统[参考论文公式24]。

  

1. 对`_ivMap`进行遍历，如果顶点的`margin`标志为`false`，则认为是`Pose`，否则，认为是`Landmark`，所以在使用g2o的时候千万要注意，不要想当然的认为g2o会帮助我们区分`Pose`和`Landmark`。g2o默认边缘化掉landmark，且它们的顺序（即id）在机器人位姿之后，所以前面必须初始化为PoseMatrixType。

  

2. 遍历多次图来构建`Hpp，Hll`等矩阵，每个矩阵的类型都是`SparseBlockMatrix`类型的：

  > g2o默认路标点的vertex都在位姿的vertex之后（状态向量中的下标）。所以可以看到不论是《十四讲》还是ORB-SLAM，都是先添加机器人位姿的vertex，再添加路标点的vertex。

* 第一次遍历整张图（所有节点）来得到*机器人位姿和路标点的个数*，并且按顺序确定每个变量在（各自）海塞矩阵`(_Hpp, _Hll) `中的位置和占据的大小；

* 第二次遍历整张图来获得*每个节点的海塞矩阵*，按之前遍历得到的信息将之放入`_Hpp`或`_Hll`中恰当的位置；

* 第三次遍历所有待优化的边，这一次，是为了获得`N(=2)`个节点间的*协方差矩阵*，来构建`_Hpl`矩阵。

3. 如果不进行schur补，那么到此就结束了。否则，我们要再一次遍历整张图，构建一个schur消元的中间矩阵，`_Hschur`

这时，我们只处理要被边缘化的节点。（g2o只支持marg路标点。）一个路标点要被marg点，则会在观测到它的n个相机位姿之间引入fill-in. 因此，要遍历被marg的路标点连接的边和这些边所连接的其他节点，在这些节点之间记录后面会有fill-in，相当于建立一个索引表，方便后续操作。然后根据这个索引表事先建立好_Hschur矩阵。

  
  
```cpp
template <typename Traits>

bool BlockSolver<Traits>::buildStructure(bool zeroBlocks)

{

  

  size_t sparseDim = 0; //稀疏矩阵总维度：dim_p * n_p + dim_l * n_l

  _numPoses=0;

  _numLandmarks=0;

  _sizePoses=0;

  _sizeLandmarks=0;

  

  int* blockPoseIndices = new int[_optimizer->indexMapping().size()];

  int* blockLandmarkIndices = new int[_optimizer->indexMapping().size()];

  

  for (size_t i = 0; i < _optimizer->indexMapping().size(); ++i) {

    //

    OptimizableGraph::Vertex* v = _optimizer->indexMapping()[i];

    int dim = v->dimension();

    // marginalized区分顶点类型，默认边缘化掉landmark

    if (! v->marginalized()){

      v->setColInHessian(_sizePoses);

      _sizePoses+=dim;

      blockPoseIndices[_numPoses]=_sizePoses;

      ++_numPoses;

    } else {

      v->setColInHessian(_sizeLandmarks);

      _sizeLandmarks+=dim;

      blockLandmarkIndices[_numLandmarks]=_sizeLandmarks;

      ++_numLandmarks;

    }

    sparseDim += dim;

  }

  resize(blockPoseIndices, _numPoses, blockLandmarkIndices, _numLandmarks, sparseDim);

  delete[] blockLandmarkIndices;

  delete[] blockPoseIndices;

  

  // allocate the diagonal on Hpp and Hll

  int poseIdx = 0;

  int landmarkIdx = 0;

  for (size_t i = 0; i < _optimizer->indexMapping().size(); ++i) {

    OptimizableGraph::Vertex* v = _optimizer->indexMapping()[i];

    if (! v->marginalized()){

      PoseMatrixType* m = _Hpp->block(poseIdx, poseIdx, true);

      if (zeroBlocks)

        m->setZero();

      v->mapHessianMemory(m->data()); //分配数据

      ++poseIdx;

    } else {

      LandmarkMatrixType* m = _Hll->block(landmarkIdx, landmarkIdx, true);

      if (zeroBlocks)

        m->setZero();

      v->mapHessianMemory(m->data());

      ++landmarkIdx;

    }

  }

  

  // temporary structures for building the pattern of the Schur complement

  SparseBlockMatrixHashMap<PoseMatrixType>* schurMatrixLookup = 0;

  if (_doSchur) {

    schurMatrixLookup = new SparseBlockMatrixHashMap<PoseMatrixType>(_Hschur->rowBlockIndices(), _Hschur->colBlockIndices());

    schurMatrixLookup->blockCols().resize(_Hschur->blockCols().size());

  }

  

  // here we assume that the landmark indices start after the pose ones

  // create the structure in Hpp, Hll and in Hpl

  for (SparseOptimizer::EdgeContainer::const_iterator it=_optimizer->activeEdges().begin(); it!=_optimizer->activeEdges().end(); ++it){

    OptimizableGraph::Edge* e = *it;

  

    for (size_t viIdx = 0; viIdx < e->vertices().size(); ++viIdx) {

  

      OptimizableGraph::Vertex* v1 = (OptimizableGraph::Vertex*) e->vertex(viIdx);

      int ind1 = v1->hessianIndex();

      if (ind1 == -1)

        continue;

  

      int indexV1Bak = ind1;

      for (size_t vjIdx = viIdx + 1; vjIdx < e->vertices().size(); ++vjIdx) {

        OptimizableGraph::Vertex* v2 = (OptimizableGraph::Vertex*) e->vertex(vjIdx);

        int ind2 = v2->hessianIndex();

        if (ind2 == -1)

          continue;

        ind1 = indexV1Bak;

        bool transposedBlock = ind1 > ind2;

        if (transposedBlock){ // make sure, we allocate the upper triangle block

          std::swap(ind1, ind2);

        }

        // 构建Hpp, Hll, Hpl

        if (! v1->marginalized() && !v2->marginalized()){

          PoseMatrixType* m = _Hpp->block(ind1, ind2, true);

          if (zeroBlocks)

            m->setZero();

          e->mapHessianMemory(m->data(), viIdx, vjIdx, transposedBlock);

          if (_Hschur) {// assume this is only needed in case we solve with the schur complement

            schurMatrixLookup->addBlock(ind1, ind2);

          }

        } else if (v1->marginalized() && v2->marginalized()){

          // RAINER hmm.... should we ever reach this here????

          LandmarkMatrixType* m = _Hll->block(ind1-_numPoses, ind2-_numPoses, true);

          if (zeroBlocks)

            m->setZero();

          e->mapHessianMemory(m->data(), viIdx, vjIdx, false);

        } else {

          if (v1->marginalized()){

            PoseLandmarkMatrixType* m = _Hpl->block(v2->hessianIndex(),v1->hessianIndex()-_numPoses, true);

            if (zeroBlocks)

              m->setZero();

            e->mapHessianMemory(m->data(), viIdx, vjIdx, true); // transpose the block before writing to it

          } else {

            PoseLandmarkMatrixType* m = _Hpl->block(v1->hessianIndex(),v2->hessianIndex()-_numPoses, true);

            if (zeroBlocks)

              m->setZero();

            e->mapHessianMemory(m->data(), viIdx, vjIdx, false); // directly the block

          }

        }

      }

    }

  }

  

  // 如果不进行schur补，那么到此就结束了

  if (! _doSchur) {

    delete schurMatrixLookup;

    return true;

  }

  // 否则，我们要再一次遍历整张图，构建一个schur消元的中间矩阵，_Hschur

  _DInvSchur->diagonal().resize(landmarkIdx);

  _Hpl->fillSparseBlockMatrixCCS(*_HplCCS);

  

  for (OptimizableGraph::Vertex* v : _optimizer->indexMapping()) {

    //只处理要被边缘化的节点,g2o只支持marg路标点

    if (v->marginalized()){

      // 在观测到它的n个相机位姿之间引入fill-in. 因此，要遍历被marg的路标点连接的边和这些边所连接的其他节点

      const HyperGraph::EdgeSet& vedges=v->edges();

      for (HyperGraph::EdgeSet::const_iterator it1=vedges.begin(); it1!=vedges.end(); ++it1){

        // 遍历边所连接的其他节点

        for (size_t i=0; i<(*it1)->vertices().size(); ++i)

        {

          OptimizableGraph::Vertex* v1= (OptimizableGraph::Vertex*) (*it1)->vertex(i);

          if (v1->hessianIndex()==-1 || v1==v)

            continue;

          // 建立一个索引表schurMatrixLookup

          for  (HyperGraph::EdgeSet::const_iterator it2=vedges.begin(); it2!=vedges.end(); ++it2){

            for (size_t j=0; j<(*it2)->vertices().size(); ++j)

            {

              OptimizableGraph::Vertex* v2= (OptimizableGraph::Vertex*) (*it2)->vertex(j);

              if (v2->hessianIndex()==-1 || v2==v)

                continue;

              int i1=v1->hessianIndex();

              int i2=v2->hessianIndex();

              if (i1<=i2) {

                schurMatrixLookup->addBlock(i1, i2);

              }

            }

          }

        }

      }

    }

  }

  // 根据这个索引表事先建立好_Hschur矩阵。

  _Hschur->takePatternFromHash(*schurMatrixLookup);

  delete schurMatrixLookup;

  _Hschur->fillSparseBlockMatrixCCSTransposed(*_HschurTransposedCCS);

  

  return true;

}

```
  

## buildSystem

  

buildStructure只有在还没开始迭代的时候先调用一次。然后，每次迭代求解之前，都需要调用buildSystem函数来初始化。

  

因为通过buildStructure函数，整个系统的H矩阵的结构我们已经构建好了。现在，经过之前的迭代求解，**观测量**的值发生了变化（或者没经过求解，但也要把**初始化的值添加**到构建好的结构里），因此要对整个系统（的值）进行**更新**， 也就是将增量方程$HΔx=−b$中的`H矩阵`和`b向量`重新赋值。

  

具体过程如下。

  

* 先遍历所有节点，对每个节点，由`clearQuadraticForm函数`清空之前的H和b，并且清空`_Hpp`矩阵。如果要进行舒尔补，还要清空`_Hll`和`_Hpl`矩阵。

  

* 然后遍历所有边，重新又`lineaizeOplus函数`进行线性化操作,计算该边误差所产生的`jacobian`矩阵，并`constructQuadraticForm函数`构建H和b。

> 根据公式$H=J^TWJ$计算每个顶点的`_hessian`矩阵，$b=J^TWδ$计算b向量。如果该边是个二元边，且两个定点都没有被`fix`的时候，还会根据$H=J^T_1WJ$计算相交部分的`_hessian`矩阵。

  

* 最后遍历所有的顶点的`b`并将其真值拷贝到增量方程的b内。

此时，大的H矩阵已经完成更新，还需要遍历所有节点来**更新b向量**

> 因为BaseVertex中，`_hessian`是`Eigen::Map`类型，而`_b`是`Eigen::Matrix`类型，因此虽然没有显式地更新系统的H矩阵，但在遍历边时，更新的H就已经更新在`_Hpp`等变量里面了

  
  

```c++

template <typename Traits>

bool BlockSolver<Traits>::buildSystem()

{

  // clear b vector

# ifdef G2O_OPENMP

# pragma omp parallel for default (shared) if (_optimizer->indexMapping().size() > 1000)

# endif

  for (int i = 0; i < static_cast<int>(_optimizer->indexMapping().size()); ++i) {

    OptimizableGraph::Vertex* v=_optimizer->indexMapping()[i];

    assert(v);

    v->clearQuadraticForm();

  }

  _Hpp->clear();

  if (_doSchur) {

    _Hll->clear();

    _Hpl->clear();

  }

  

  // resetting the terms for the pairwise constraints

  // built up the current system by storing the Hessian blocks in the edges and vertices

# ifndef G2O_OPENMP

  // no threading, we do not need to copy the workspace

  JacobianWorkspace& jacobianWorkspace = _optimizer->jacobianWorkspace();

# else

  // if running with threads need to produce copies of the workspace for each thread

  JacobianWorkspace jacobianWorkspace = _optimizer->jacobianWorkspace();

# pragma omp parallel for default (shared) firstprivate(jacobianWorkspace) if (_optimizer->activeEdges().size() > 100)

# endif

  for (int k = 0; k < static_cast<int>(_optimizer->activeEdges().size()); ++k) {

    OptimizableGraph::Edge* e = _optimizer->activeEdges()[k];

    e->linearizeOplus(jacobianWorkspace); // jacobian of the nodes' oplus (manifold)

    e->constructQuadraticForm();

#  ifndef NDEBUG

    for (size_t i = 0; i < e->vertices().size(); ++i) {

      const OptimizableGraph::Vertex* v = static_cast<const OptimizableGraph::Vertex*>(e->vertex(i));

      if (! v->fixed()) {

        bool hasANan = arrayHasNaN(jacobianWorkspace.workspaceForVertex(i), e->dimension() * v->dimension());

        if (hasANan) {

          std::cerr << "buildSystem(): NaN within Jacobian for edge " << e << " for vertex " << i << std::endl;

          break;

        }

      }

    }

#  endif

  }

  

  // flush the current system in a sparse block matrix

  for (int i = 0; i < static_cast<int>(_optimizer->indexMapping().size()); ++i) {

    OptimizableGraph::Vertex* v=_optimizer->indexMapping()[i];

    int iBase = v->colInHessian();

    if (v->marginalized())

      iBase+=_sizePoses;

    v->copyB(_b+iBase);

  }

  

  return 0;

}

```

</details>

  
  

通用版本makeHessian

```c++

MatXX H(MatXX::Zero(size, size)); // size = 维度x顶点数

VecX b(VecX::Zero(size));

  

for (edge: edges_) {

    // 遍历边连接的顶点

    for (v_i: edge.verticies) {

        // Hessian 里不需要添加fix的信息，也就是它的雅克比为 0

        if (v_i->IsFixed()) continue;    

  

        // 遍历其他顶点，得到 H = J_i^T * W * J_j

        MatXX JtW = jacobian_i.transpose() * edge.information;

        for (v_j : edge.verticies) { // j start from i

            if (v_j->IsFixed()) continue;

  

            MatXX hessian = JtW * jacobian_j;

  

            // ！！所有的信息矩阵叠加起来

            H.block(index_i, index_j, dim_i, dim_j).noalias() += hessian;

            if (j != i) {

                // 对称的下三角

                H.block(index_j, index_i, dim_j, dim_i).noalias() += hessian.transpose();

            }

        }

        // 得到b向量

        b.segment(index_i, dim_i).noalias() -= JtW * edge.residual;

    }

}

```

  
  

## solve

依靠块求解器`BlockSolver`的`solve`函数，下面是过程：

1. 判断是否要做schur消元，如果不做的话，则认为整个图中没有要`margin`的点，，直接调用`_linearSolver`的`solve`函数来求解`Hx=b`就可以了

  

2. 如果要进行`schur`消元，则在后面构建出schur需要的矩阵和向量.

  

> 由于路标点对应的H矩阵显然是个稀疏的`block diagonal matrix`，因此我们遍历路标点，单独对其`_Hll`矩阵进行求逆（即单独求一个3*3矩阵的逆）。

> 然后按照公式进行`schur补`相关矩阵的计算。这里先求出的机器人位姿，因此先计算其相关的矩阵`（_Hschur, _bschur等`）；然后调用`_linearSolver`，输入相关矩阵进行求解。

> 如果机器人位姿求解成功了，就按照公式将之反代回`schur补`公式中，对路标点的位置进行求解。

  
  
  
  
  

## 其他函数

  

- updateStructure函数

这是外部传入一组节点和边，以此来构建大的H矩阵。这个函数不支持schur补，因此比buildStructure函数简单多了，主要就是完成buildStruct函数的那三个步骤。而且由于不进行舒尔补，所以步骤1是不需要的，就当所有节点都是机器人位置，然后挨个放进去就可以。

- setLambda和restoreDiagonal这一对函数

将H矩阵备份，然后在主对角元素上加上lambda或者从备份中恢复原来的H矩阵。init函数就是清空各个矩阵块，然后调用_linearSolver的init函数即可。

  
  
  