

##  `scalar.h`
`using Scalar = double;`

##  `fixed_vector.h`

```c++
#define HOST_DEVICE __host__ __device__ inline
template <typename T, int N>
struct Vec
{
    HOST_DEVICE Vec(const T* values) { for (int i = 0; i < N; i++) data[i] = values[i]; }
    
    T data[N];
}
```


##  `device_buffer.h`

- `T* data_` :  数据首地址
- `size_t size_, capacity_` : 数据大小
- `bool allocated_` ： 是否分配
```mermaid
graph TD
%%此图示由列表文本转换而成！%%





```
```c++
template <typename T>
class DeviceBuffer
{
public:
	// 分配GPU内存
	void allocate(size_t count)
	{
		if (data_ && capacity_ >= count)
			return;

		destroy();
		CUDA_CHECK(cudaMalloc(&data_, sizeof(T) * count));
		capacity_ = count;
		allocated_ = true;
	}


	void resize(size_t size)
	{
		allocate(size);
		size_ = size;
	}

	void map(size_t size, void* data)
	{
		data_ = (T*)data;
		size_ = size;
		allocated_ = false;
	}

	void assign(size_t size, const void* h_data)
	{
		resize(size);
		upload((T*)h_data);
	}

	void upload(const T* h_data)
	void download(T* h_data) const
	void fillZero()
};

```

##  `device_matrix.h`

### BlockPtr：  连续矩阵块的索引

``` c++
template <typename T, int BLOCK_ROWS, int BLOCK_COLS>
class BlockPtr
{
public:

	static const int BLOCK_AREA = BLOCK_ROWS * BLOCK_COLS;
	__device__ T* at(int i) { return data_ + i * BLOCK_AREA; }
	__device__ const T* at(int i) const { return data_ + i * BLOCK_AREA; }

private:
	T* data_;  //GPU 内存，连续矩阵块
};
```



### DeviceBlockMatrix：

``` c++
template <typename T, int BLOCK_ROWS, int BLOCK_COLS, int ORDER>
class DeviceBlockMatrix
{
public:

	static const int BLOCK_AREA = BLOCK_ROWS * BLOCK_COLS;
	using BlockPtrT = BlockPtr<T, BLOCK_ROWS, BLOCK_COLS>;

	DeviceBlockMatrix() : rows_(0), cols_(0), nnz_(0), outerSize_(0), innerSize_(0) {}
	DeviceBlockMatrix(int rows, int cols) : nnz_(0) { resize(rows, cols); }

	void resize(int rows, int cols)
	{
		rows_ = rows;
		cols_ = cols;
		outerSize_ = ORDER == ROW_MAJOR ? rows : cols;
		innerSize_ = ORDER == ROW_MAJOR ? cols : rows;
		outerIndices_.resize(outerSize_ + 1);
	}

	void resizeNonZeros(int nnz)
	{
		nnz_ = nnz;
		values_.resize(nnz * BLOCK_AREA);
		innerIndices_.resize(nnz);
	}

	void upload(const T* values, const int* outerIndices, const int* innerIndices)
	{
		if (values)
			values_.upload(values);
		if (outerIndices)
			outerIndices_.upload(outerIndices);
		if (innerIndices)
			innerIndices_.upload(innerIndices);
	}

	void download(T* values, int* outerIndices, int* innerIndices) const
	{
		if (values)
			values_.download(values);
		if (outerIndices)
			outerIndices_.download(outerIndices);
		if (innerIndices)
			innerIndices_.download(innerIndices);
	}

	void fillZero()
	{
		values_.fillZero();
	}

	T* values() { return values_.data(); }
	int* outerIndices() { return outerIndices_.data(); }
	int* innerIndices() { return innerIndices_.data(); }

	const T* values() const { return values_.data(); }
	const int* outerIndices() const { return outerIndices_.data(); }
	const int* innerIndices() const { return innerIndices_.data(); }

	int rows() const { return rows_; }
	int cols() const { return cols_; }
	int nnz() const { return nnz_; }

	operator BlockPtrT() const { return BlockPtrT((T*)values_.data()); }

private:

	DeviceBuffer<T> values_;
	DeviceBuffer<int> outerIndices_, innerIndices_;
	int rows_, cols_, nnz_, outerSize_, innerSize_;
};
```

### DeviceBlockVector：向量类型

- `DeviceBuffer<T> values_` : 数据内存
- `int size_` : 

```c++


template <typename T, int BLOCK_ROWS, int BLOCK_COLS>
class DeviceBlockVector
{
public:

	static const int BLOCK_AREA = BLOCK_ROWS * BLOCK_COLS;
	using BlockPtrT = BlockPtr<T, BLOCK_ROWS, BLOCK_COLS>;

	DeviceBlockVector() : size_(0) {}
	DeviceBlockVector(int size) { resize(size); }

	void resize(int size)
	{
		size_ = size;
		values_.resize(size * BLOCK_AREA);
	}

	void map(int size, T* data)
	{
		size_ = size;
		values_.map(size * BLOCK_AREA, data);
	}

	void fillZero()
	{
		values_.fillZero();
	}

	void copyTo(DeviceBlockVector& rhs) const
	{
		values_.copyTo(rhs.values());
	}

	operator BlockPtrT() const { return BlockPtrT((T*)values_.data()); }

};

```


### GpuVecAny： 

``` c++
class GpuVecAny
{
public:

	GpuVecAny() : ptr_(nullptr) {}
	template <typename T> GpuVecAny(const GpuVec<T>& vec) : ptr_((void*)&vec) {}
	template <typename T> GpuVec<T>& getRef() const { return *((GpuVec<T>*)ptr_); }
	template <typename T> const GpuVec<T>& getCRef() const { return *((GpuVec<T>*)ptr_); }

private:

	void* ptr_;
};
```


### 类型

```c++
template <typename T>
using GpuVec = DeviceBuffer<T>;

using GpuVec1d = GpuVec<Scalar>;
using GpuVec2d = GpuVec<Vec2d>;

using GpuVec1b = GpuVec<uint8_t>;

using GpuHplBlockMat = DeviceBlockMatrix<Scalar, PDIM, LDIM, COL_MAJOR>;
using GpuHscBlockMat = DeviceBlockMatrix<Scalar, PDIM, PDIM, ROW_MAJOR>;

using GpuPxPBlockVec = DeviceBlockVector<Scalar, PDIM, PDIM>;
using GpuLxLBlockVec = DeviceBlockVector<Scalar, LDIM, LDIM>;
using GpuPxLBlockVec = DeviceBlockVector<Scalar, PDIM, LDIM>;
using GpuPx1BlockVec = DeviceBlockVector<Scalar, PDIM, 1>;
using GpuLx1BlockVec = DeviceBlockVector<Scalar, LDIM, 1>;

```

